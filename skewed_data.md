# Skewed Classes

If a class has a lot more training examples than the other.

## Precision Term

(True positives)/(predicted positives)

> of all we predicted with class X what fraction actually is
> in class X?

## Recall Term

(True positives)/(actual positives)

> of all in class X, what fraction was actually predicted
> to be in class X?

## F1 score (F-score)

The F1 score, also known as the F-score or F-measure, is a measure of the
accuracy of a classifier. It is calculated as the harmonic mean of precision
and recall.

The F1 score is a balance between precision and recall, and is often used as a
summary measure of the performance of a classifier. It is calculated as:

F1 = 2 * (precision * recall) / (precision + recall)

A value of 0 indicates that the classifier made no true positive predictions,
and a value of 1 indicates that the classifier made all true positive
predictions and no false positive predictions.
